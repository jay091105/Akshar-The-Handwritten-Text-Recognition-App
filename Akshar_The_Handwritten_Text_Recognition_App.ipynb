{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGiBRlxdaQxD"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSTELnv-aQxE"
      },
      "source": [
        "============================================================================================<br>\n",
        "HANDWRITTEN / CLEAN-WRITING TEXT RECOGNITION â€” WITH FULL PREPROCESSING<br>\n",
        "USING TrOCR ONLY (NO EASYOCR)<br>\n",
        "============================================================================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrcCiefcaQxG"
      },
      "source": [
        "-----------------------------<br>\n",
        "IMPORTS<br>\n",
        "-----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfmHIe0saQxG"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgOZbw96aQxH"
      },
      "source": [
        "Optional imports with error handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "optz01RCaQxH"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    MATPLOTLIB_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MATPLOTLIB_AVAILABLE = False\n",
        "    print(\"Warning: matplotlib not available. Visualization will be skipped.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCxAuKQ6aQxH"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "except ImportError:\n",
        "    print(\"Error: transformers library not found. Please install: pip install transformers\")\n",
        "    sys.exit(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVQzppzMaQxI"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from googletrans import Translator\n",
        "except ImportError:\n",
        "    print(\"Error: googletrans library not found. Please install: pip install googletrans==4.0.0-rc1\")\n",
        "    sys.exit(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_AUYXTWaQxI"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from gtts import gTTS\n",
        "except ImportError:\n",
        "    print(\"Error: gTTS library not found. Please install: pip install gtts\")\n",
        "    sys.exit(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mOZBUV5aQxI"
      },
      "source": [
        "-----------------------------<br>\n",
        "DEVICE CHECK<br>\n",
        "-----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAnZ2rFKaQxI"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y40otmApaQxI"
      },
      "source": [
        "-----------------------------<br>\n",
        "LOAD TrOCR MODEL<br>\n",
        "-----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjIoEbimaQxI"
      },
      "outputs": [],
      "source": [
        "print(\"Loading TrOCR model (this may take a while)...\")\n",
        "try:\n",
        "    processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-printed\")\n",
        "    model = VisionEncoderDecoderModel.from_pretrained(\n",
        "        \"microsoft/trocr-base-printed\",\n",
        "        ignore_mismatched_sizes=True\n",
        "    ).to(device)\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    print(\"Model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading TrOCR model: {e}\")\n",
        "    print(\"Please ensure you have internet connection for first-time download.\")\n",
        "    sys.exit(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6J1tTo5PaQxJ"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    translator = Translator()\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not initialize translator: {e}\")\n",
        "    translator = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTOgJkMkaQxJ"
      },
      "source": [
        "-----------------------------<br>\n",
        "PREPROCESSING FUNCTION<br>\n",
        "-----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb1j_OUraQxJ"
      },
      "outputs": [],
      "source": [
        "def preprocess_image_opencv(image_path):\n",
        "    \"\"\"\n",
        "    Enhanced preprocessing pipeline for better OCR accuracy.\n",
        "    Includes: denoising, binarization, contrast enhancement, and sharpening.\n",
        "    \"\"\"\n",
        "    # Read image using OpenCV\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Could not read image from {image_path}. Please check the file path.\")\n",
        "\n",
        "    # Handle both color and grayscale images\n",
        "    if len(img.shape) == 3:\n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = img\n",
        "\n",
        "    # Denoise (Gaussian Blur) - reduces noise\n",
        "    blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "\n",
        "    # Additional denoising using Non-local Means (optional, slower but better)\n",
        "    # denoised = cv2.fastNlMeansDenoising(blur, None, 10, 7, 21)\n",
        "\n",
        "    # Morphological operations to clean up the image\n",
        "    kernel = np.ones((2, 2), np.uint8)\n",
        "    cleaned = cv2.morphologyEx(blur, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # Adaptive Threshold (binarization) - better for varying lighting\n",
        "    thresh = cv2.adaptiveThreshold(\n",
        "        cleaned, 255,\n",
        "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "        cv2.THRESH_BINARY,\n",
        "        31, 5\n",
        "    )\n",
        "\n",
        "    # Contrast Enhancement using CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "    enhanced = clahe.apply(thresh)\n",
        "\n",
        "    # Additional sharpening for better text clarity\n",
        "    kernel_sharpen = np.array([[-1, -1, -1],\n",
        "                               [-1,  9, -1],\n",
        "                               [-1, -1, -1]])\n",
        "    sharpened = cv2.filter2D(enhanced, -1, kernel_sharpen)\n",
        "\n",
        "    # Resize (maintain aspect ratio) - TrOCR works better with larger images\n",
        "    h, w = sharpened.shape\n",
        "    scale = 1024 / max(h, w)\n",
        "    new_w, new_h = int(w * scale), int(h * scale)\n",
        "    resized = cv2.resize(sharpened, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Convert to PIL image (TrOCR needs RGB)\n",
        "    pil_img = Image.fromarray(resized).convert(\"RGB\")\n",
        "    return pil_img, enhanced, resized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twQiszOjaQxJ"
      },
      "source": [
        "-----------------------------<br>\n",
        "OCR RECOGNITION FUNCTION<br>\n",
        "-----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMs9vKHpaQxJ"
      },
      "outputs": [],
      "source": [
        "def recognize_image(img_pil):\n",
        "    pixel_values = processor(img_pil, return_tensors=\"pt\").pixel_values.to(device)\n",
        "    generated_ids = model.generate(pixel_values, max_length=512)\n",
        "    text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0WPg6fiaQxJ"
      },
      "source": [
        "-----------------------------<br>\n",
        "SET IMAGE PATH<br>\n",
        "-----------------------------<br>\n",
        "Change this to your image path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etQeGM0KaQxJ"
      },
      "outputs": [],
      "source": [
        "IMAGE_PATH = \"sample.jpg\"  # Default local path\n",
        "# Or specify as command line argument: python sgp_sem_5.py path/to/image.jpg\n",
        "if len(sys.argv) > 1:\n",
        "    IMAGE_PATH = sys.argv[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-7dHlEnaQxJ"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(IMAGE_PATH):\n",
        "    print(f\"Error: Image file not found: {IMAGE_PATH}\")\n",
        "    print(\"Please provide a valid image path.\")\n",
        "    sys.exit(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_YysHVyaQxJ"
      },
      "outputs": [],
      "source": [
        "print(\"Reading:\", IMAGE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E4r-XDQaQxK"
      },
      "source": [
        "-----------------------------<br>\n",
        "RUN PREPROCESSING<br>\n",
        "-----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dx4TIpzBaQxK"
      },
      "outputs": [],
      "source": [
        "print(\"\\n Preprocessing image...\")\n",
        "try:\n",
        "    pre_img, thresh_img, resized_img = preprocess_image_opencv(IMAGE_PATH)\n",
        "    print(\" Preprocessing complete! (Grayscale, Denoising, Thresholding, CLAHE, Sharpening, Resizing)\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during preprocessing: {e}\")\n",
        "    sys.exit(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjrgJSCkaQxK"
      },
      "source": [
        "-----------------------------<br>\n",
        "SHOW THE PREPROCESSING STAGES<br>\n",
        "-----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKCKLjxOaQxK"
      },
      "outputs": [],
      "source": [
        "if MATPLOTLIB_AVAILABLE:\n",
        "    try:\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(thresh_img, cmap='gray')\n",
        "        plt.title(\"Threshold + CLAHE\", fontsize=14)\n",
        "        plt.axis('off')\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(resized_img, cmap='gray')\n",
        "        plt.title(\"Resized (Aspect Ratio Preserved)\", fontsize=14)\n",
        "        plt.axis('off')\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(pre_img)\n",
        "        plt.title(\"Final Image Sent to TrOCR\", fontsize=14)\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"preprocessing_stages.png\", dpi=150, bbox_inches='tight')\n",
        "        plt.close()  # Close figure to free memory\n",
        "        print(\"Preprocessing visualization saved as: preprocessing_stages.png\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not save preprocessing stages visualization: {e}\")\n",
        "else:\n",
        "    print(\"Skipping preprocessing visualization (matplotlib not available)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmbrsA-OaQxK"
      },
      "source": [
        "-----------------------------<br>\n",
        "RUN OCR<br>\n",
        "-----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYzArTuEaQxK"
      },
      "outputs": [],
      "source": [
        "print(\"\\n Running OCR recognition...\")\n",
        "try:\n",
        "    text = recognize_image(pre_img)\n",
        "\n",
        "    print(\"\\n==============================\")\n",
        "    print(\"RECOGNIZED TEXT:\")\n",
        "    print(\"==============================\")\n",
        "    print(text)\n",
        "    print(\"==============================\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during OCR recognition: {e}\")\n",
        "    sys.exit(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQQSo-3MaQxK"
      },
      "source": [
        "-----------------------------<br>\n",
        "SHOW ORIGINAL IMAGE<br>\n",
        "-----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORTNKO71aQxK"
      },
      "outputs": [],
      "source": [
        "if MATPLOTLIB_AVAILABLE:\n",
        "    try:\n",
        "        orig = Image.open(IMAGE_PATH)\n",
        "        plt.figure(figsize=(8,6))\n",
        "        plt.imshow(orig)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(\"Original Input Image\", fontsize=16)\n",
        "        plt.savefig(\"original_image.png\", dpi=150, bbox_inches='tight')\n",
        "        plt.close()  # Close figure to free memory\n",
        "        print(\"Original image saved as: original_image.png\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not save original image visualization: {e}\")\n",
        "else:\n",
        "    print(\"Skipping original image visualization (matplotlib not available)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILEeBlxmaQxK"
      },
      "source": [
        "-----------------------------<br>\n",
        "TEXT â†’ SPEECH (ORIGINAL)<br>\n",
        "-----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECXpV8-EaQxL"
      },
      "outputs": [],
      "source": [
        "if text.strip():\n",
        "    try:\n",
        "        output_dir = \"output\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        speech_path = os.path.join(output_dir, \"original_speech.mp3\")\n",
        "\n",
        "        tts = gTTS(text=text, lang=\"en\")\n",
        "        tts.save(speech_path)\n",
        "        print(f\"\\n Speech saved: {speech_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not generate speech: {e}\")\n",
        "else:\n",
        "    print(\"No text detected to speak.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pEa7qWmaQxL"
      },
      "source": [
        "-----------------------------<br>\n",
        "TRANSLATION + SPEECH<br>\n",
        "-----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvDqTSuvaQxL"
      },
      "outputs": [],
      "source": [
        "target_lang = \"hi\"   # Hindi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yYhdllFaQxL"
      },
      "outputs": [],
      "source": [
        "if text.strip():\n",
        "    if translator is None:\n",
        "        print(\"Translation skipped: Translator not available\")\n",
        "    else:\n",
        "        try:\n",
        "            print(f\"\\n Translating to {target_lang}...\")\n",
        "            translated = translator.translate(text, dest=target_lang).text\n",
        "\n",
        "            print(\"\\n==============================\")\n",
        "            print(\"TRANSLATED TEXT:\")\n",
        "            print(\"==============================\")\n",
        "            print(translated)\n",
        "            print(\"==============================\")\n",
        "\n",
        "            output_dir = \"output\"\n",
        "            os.makedirs(output_dir, exist_ok=True)\n",
        "            translated_speech_path = os.path.join(output_dir, \"translated_speech.mp3\")\n",
        "\n",
        "            tts = gTTS(text=translated, lang=target_lang)\n",
        "            tts.save(translated_speech_path)\n",
        "            print(f\"\\n Translated speech saved: {translated_speech_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Translation failed: {e}\")\n",
        "            print(\"Note: Translation may fail due to API rate limits. The OCR text is still available above.\")\n",
        "else:\n",
        "    print(\"No text to translate.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNykficOaQxL"
      },
      "outputs": [],
      "source": [
        "print(\"\\n Processing complete!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}